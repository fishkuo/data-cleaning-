# data-cleaning

- add column source
- add column type
- add column alias
- add column url(連回主文)
- add column clean_text -> clean out everything other than Chinese character
- add column token -> tokenize data in column no_stop
- add column no_stop -> remove stopwords in column token
- add column keywords -> keywords of the document based on term frequency analysis
- add column sentiment -> sentiment analysis(positive, nuetral, negative)
- save as csv
- note: 須將模型[檔案](https://drive.google.com/drive/folders/1awuMjlDNa-RktSFpjPArv6nUzJP9E7vB?usp=sharing)放在路徑中
# data-cleaning-
